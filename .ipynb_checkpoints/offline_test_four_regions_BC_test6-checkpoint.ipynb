{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuffed-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from data.utils import load_training_datasets\n",
    "import os\n",
    "\n",
    "# %env MLFLOW_TRACKING_URI /scratch/ag7531/mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806be2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d231a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=False #test with small batch, big batch needs .py to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dd4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_test==True:\n",
    "  raw_data = xr.open_zarr('/scratch/cimes/cz3321/MOM6/experiments/double_gyre/postprocess/offline_test/cm2p6/forcing.zarr')\n",
    "  # raw_data = xr.open_zarr('/scratch/gpfs/cz3321/CM2P6/forcing.zarr') \n",
    "  raw_datasets = load_training_datasets(raw_data, 'training_subdomains.yaml')\n",
    "else:\n",
    "  # raw_data = xr.open_zarr('/scratch/cimes/cz3321/MOM6/experiments/double_gyre/postprocess/offline_test/cm2p6/forcing.zarr')\n",
    "  raw_data = xr.open_zarr('/scratch/gpfs/cz3321/CM2P6/forcing.zarr')\n",
    "  raw_datasets = load_training_datasets(raw_data, 'training_subdomains.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1004fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_test==False:\n",
    "  first_dataset = raw_datasets[0]\n",
    "\n",
    "  # #pick randomly\n",
    "  # np.random.seed(42)\n",
    "  # random_indices = np.random.choice(first_dataset.time.size, 1000, replace=False)\n",
    "\n",
    "  #pick test dataset (20% in the end)\n",
    "  start_index = int(first_dataset.time.size*0.8)\n",
    "  random_indices = slice(start_index, None)\n",
    "\n",
    "  random_snapshots = first_dataset.isel(time=random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b609b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_test==False:\n",
    "  low_rez = random_snapshots\n",
    "else:\n",
    "  low_rez = raw_datasets[0]\n",
    "u = low_rez['usurf']\n",
    "v = low_rez['vsurf']\n",
    "# u = prog['u'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133db3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In load_paper_net()\n",
      "After load_model_cls()\n",
      "After transformation\n",
      "After mlflow.tracking.MlflowClient()\n",
      "Loading final transformation\n",
      "After download_artifacts()\n",
      "FullyCNN_BC\n",
      "FullyCNN_BC(\n",
      "  (conv1): Conv2d(2, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv8): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (final_transformation): SoftPlusTransform(tensor(0.0597, grad_fn=<SoftplusBackward>))\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FullyCNN_BC(\n",
       "  (conv1): Conv2d(2, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv8): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (final_transformation): SoftPlusTransform(tensor(0.0597, grad_fn=<SoftplusBackward>))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "#load the neural network\n",
    "from torch.nn import Parameter\n",
    "batch_norm = 0\n",
    "def load_model_cls(model_module_name: str, model_cls_name: str):\n",
    "    try:\n",
    "        module = importlib.import_module(model_module_name)\n",
    "        model_cls = getattr(module, model_cls_name)\n",
    "    except ModuleNotFoundError as e:\n",
    "        raise type(e)('Could not retrieve the module in which the trained model \\\n",
    "                      is defined: ' + str(e))\n",
    "    except AttributeError as e:\n",
    "        raise type(e)('Could not retrieve the model\\'s class. ' + str(e))\n",
    "    return model_cls\n",
    "def load_paper_net(device: str = 'gpu'):\n",
    "    \"\"\"\n",
    "        Load the neural network from the paper\n",
    "    \"\"\"\n",
    "    print('In load_paper_net()')\n",
    "    model_module_name = 'models.models1'\n",
    "    model_cls_name = 'FullyCNN_BC'\n",
    "    model_cls = load_model_cls(model_module_name, model_cls_name)\n",
    "    print('After load_model_cls()')\n",
    "    net = model_cls(2,4,batch_norm=batch_norm)\n",
    "    \n",
    "    # final_transform= '/scratch/cimes/cz3321/MOM6/MOM6-examples/src/MOM6/config_src/external/ML_Forpy/Forpy_CNN_GZ21/final_transformation_04292023.pth'\n",
    "    # print('After net')\n",
    "    # if device == 'cpu':\n",
    "    #     transformation = torch.load(final_transform)\n",
    "    #     print('After torch.load()')\n",
    "    # else:\n",
    "    #     transformation = pickle_artifact(MODEL_RUN_ID, 'models/transformation')\n",
    "    # net.final_transformation = transformation\n",
    "    print('After transformation')\n",
    "    # Load parameters of pre-trained model\n",
    "    print('After mlflow.tracking.MlflowClient()')\n",
    "    \n",
    "    \n",
    "    # ----------------- CHANGE THIS PATH TO TRAINED MODEL ----------------- #\n",
    "    model_file = '/scratch/cimes/cz3321/MOM6/MOM6-examples/src/MOM6/config_src/external/ML_Forpy/Forpy_CNN_GZ21/cem_6_four_regions_fixed_branch.pth'\n",
    "    # ---------------------------------------------------- #\n",
    "    \n",
    "    \n",
    "    print('Loading final transformation')\n",
    "    model_module_name = 'models.transforms'\n",
    "    model_cls_name1 = 'SoftPlusTransform'\n",
    "    model_cls = load_model_cls(model_module_name, model_cls_name1)\n",
    "    model_cls_name2 = 'PrecisionTransform'\n",
    "    model_cls1 = load_model_cls(model_module_name, model_cls_name2)\n",
    "    transform = model_cls.__new__(model_cls,)\n",
    "    model_cls1.__init__(transform,)\n",
    "    state_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    transform._min_value = Parameter(state_dict.pop('final_transformation._min_value'))\n",
    "    transform.indices = slice(2,4)\n",
    "    print('After download_artifacts()')\n",
    "    #change the key name->\n",
    "    print(model_cls_name)\n",
    "    if model_cls_name.endswith(\"_BC\"):\n",
    "        from collections import OrderedDict\n",
    "        if batch_norm == 1:\n",
    "            keys_to_delete = ['2.num_batches_tracked', '5.num_batches_tracked', '8.num_batches_tracked', '11.num_batches_tracked', '14.num_batches_tracked', '17.num_batches_tracked', '20.num_batches_tracked']\n",
    "            for key in keys_to_delete:\n",
    "                if key in state_dict:\n",
    "                    del state_dict[key]\n",
    "            new_name=[\"conv1.weight\", \"conv1.bias\", \"batch_norm1.weight\", \"batch_norm1.bias\", \"batch_norm1.running_mean\", \"batch_norm1.running_var\", \"conv2.weight\", \"conv2.bias\", \"batch_norm2.weight\", \"batch_norm2.bias\", \"batch_norm2.running_mean\", \"batch_norm2.running_var\", \"conv3.weight\", \"conv3.bias\", \"batch_norm3.weight\", \"batch_norm3.bias\", \"batch_norm3.running_mean\", \"batch_norm3.running_var\", \"conv4.weight\", \"conv4.bias\", \"batch_norm4.weight\", \"batch_norm4.bias\", \"batch_norm4.running_mean\", \"batch_norm4.running_var\", \"conv5.weight\", \"conv5.bias\", \"batch_norm5.weight\", \"batch_norm5.bias\", \"batch_norm5.running_mean\", \"batch_norm5.running_var\", \"conv6.weight\", \"conv6.bias\", \"batch_norm6.weight\", \"batch_norm6.bias\", \"batch_norm6.running_mean\", \"batch_norm6.running_var\", \"conv7.weight\", \"conv7.bias\", \"batch_norm7.weight\", \"batch_norm7.bias\", \"batch_norm7.running_mean\", \"batch_norm7.running_var\", \"conv8.weight\", \"conv8.bias\"]\n",
    "        elif batch_norm == 0:\n",
    "            new_name=[\"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"conv5.weight\", \"conv5.bias\", \"conv6.weight\", \"conv6.bias\", \"conv7.weight\", \"conv7.bias\", \"conv8.weight\", \"conv8.bias\"]\n",
    "        new_state_dict = OrderedDict()\n",
    "        i=0\n",
    "        for k, v in state_dict.items():\n",
    "            name = new_name[i]\n",
    "            new_state_dict[name] = v\n",
    "            i = i+1\n",
    "        state_dict = new_state_dict\n",
    "    net.load_state_dict(state_dict)\n",
    "    net.final_transformation = transform\n",
    "    print(net)\n",
    "    return net\n",
    "matrix_dict = {}\n",
    "net = load_paper_net('cpu')\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a3d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "from train.losses import HeteroskedasticGaussianLossV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526661e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = HeteroskedasticGaussianLossV2(n_target_channels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e085b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing.utils_bc import (create_large_test_dataset, create_test_dataset)\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44383d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets import (RawDataFromXrDataset, DatasetTransformer,\n",
    "                           Subset_, DatasetWithTransform, ComposeTransforms,\n",
    "                           MultipleTimeIndices, DatasetPartitioner)\n",
    "low_rez = low_rez.fillna(0)\n",
    "# low_rez = low_rez.isel(time=slice(0, 3))\n",
    "dataset = RawDataFromXrDataset(low_rez * 10.)\n",
    "dataset.index = 'time'\n",
    "dataset.add_input('usurf')\n",
    "dataset.add_input('vsurf')\n",
    "dataset.add_landmask_input()\n",
    "dataset.add_output('S_x')\n",
    "dataset.add_output('S_y')\n",
    "features_transform_ = ComposeTransforms()\n",
    "targets_transform_ = ComposeTransforms()\n",
    "transform = DatasetTransformer(features_transform_, targets_transform_)\n",
    "transform.fit(dataset)\n",
    "dataset = DatasetWithTransform(dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f99088",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rez['S_x']=low_rez['S_x']*dataset.xr_dataset['landmask']\n",
    "low_rez['S_y']=low_rez['S_y']*dataset.xr_dataset['landmask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbef480",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_test==True:\n",
    "  test1 = create_large_test_dataset(net.to(device=device), criterion, [dataset, ], [DataLoader(dataset)], device,mask=False, replicate=False)\n",
    "  test1 = test1.rename(dict(longitude='xu_ocean', latitude='yu_ocean'))\n",
    "  test2 = create_large_test_dataset(net.to(device=device), criterion, [dataset, ], [DataLoader(dataset)], device,mask=True, replicate=False)\n",
    "  test2 = test2.rename(dict(longitude='xu_ocean', latitude='yu_ocean'))\n",
    "  test3 = create_large_test_dataset(net.to(device=device), criterion, [dataset, ], [DataLoader(dataset)], device,mask=True, replicate=True)\n",
    "  test3 = test3.rename(dict(longitude='xu_ocean', latitude='yu_ocean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77060b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_test==True:\n",
    "  from dask.diagnostics import ProgressBar\n",
    "  with ProgressBar():\n",
    "      test1 = test1.compute()\n",
    "      test2 = test2.compute()\n",
    "      test3 = test3.compute()\n",
    "      # test3 = xr.open_dataset('test_four_regions_rpad.nc')\n",
    "else:\n",
    "   test1 = xr.open_dataset('test_four_regions_test6_nobc.nc')\n",
    "   test2 = xr.open_dataset('test_four_regions_test6_0pad.nc')\n",
    "   test3 = xr.open_dataset('test_four_regions_test6_rpad.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2_snapshot(prediction, target):\n",
    "  # return np.maximum(float(1 - (np.nanmean((target-prediction)**2)) / np.nanmean((target**2))),0)\n",
    "  return np.maximum(1 - ((target-prediction)**2) / (target**2),0)\n",
    "def MSE_snapshot(prediction, target):\n",
    "  return (target-prediction)**2\n",
    "def XSX_snapshot(prediction, target, velocity):\n",
    "  return np.abs(velocity*target-velocity*prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(test, xlim=None, ylim=None):\n",
    "    mask=dataset.isel(time=0)['landmask'].values\n",
    "    maskn=np.where(mask == 0, torch.tensor(float('nan')), mask)\n",
    "    mse = dict()\n",
    "    variance = dict()\n",
    "    r_squared = dict()\n",
    "    R2_global = dict()\n",
    "    # correlation = dict()\n",
    "    for var in ['S_x', 'S_y']:\n",
    "        mse[var] = ((test[var]*maskn - low_rez[var]*1e7*maskn)**2).mean(dim='time')\n",
    "        variance[var] = ((low_rez[var]*1e7*maskn)**2).mean(dim='time')\n",
    "        r_squared[var] = 1 - mse[var] / variance[var]\n",
    "        R2_global[var] = 1 - np.nanmean(mse[var]) / np.nanmean(variance[var])\n",
    "        # correlation[var] = xr.corr(test[var], low_rez[var]*1e7, dim='time')\n",
    "    from matplotlib.patches import Arrow, Circle\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    extent = (low_rez['xu_ocean'].min(), low_rez['xu_ocean'].max(), low_rez['yu_ocean'].min(), low_rez['yu_ocean'].max())\n",
    "    xq = test['xu_ocean']\n",
    "    yq = test['yu_ocean']\n",
    "    for i, var in enumerate(['S_x', 'S_y']):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        im = plt.imshow(r_squared[var], vmin=0., vmax=1,\n",
    "                       origin='lower', extent=extent, aspect=\"auto\")\n",
    "        plt.xlim(xq[20],xq[-20])\n",
    "        plt.ylim(yq[20],yq[-20])\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim[0],xlim[1])\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim[0],ylim[1])\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.ylabel('Latitude')\n",
    "            patches = [Circle((11, 40), radius=0.4, color='white'),\n",
    "                         Circle((18, 40), radius=0.4, color='green'),]\n",
    "            for patch in patches:\n",
    "                  im.axes.add_patch(patch)\n",
    "            plt.title('(f) $R^2$ for $S_{x}^{(mean)}$:'+f' {round(R2_global[var],3)}')\n",
    "        elif i == 1:\n",
    "            patches = [Circle((11, 40), radius=0.4, color='white'),\n",
    "                         Circle((18, 40), radius=0.4, color='green'),]\n",
    "            for patch in patches:\n",
    "                  im.axes.add_patch(patch)\n",
    "            plt.title('(d) $R^2$ for $S_{y}^{(mean)}$:'+f' {round(R2_global[var],3)}')\n",
    "        plt.xlabel('Longitude')\n",
    "\n",
    "    \n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.1, 0.025, 0.8])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, label=r'$R^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ef9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da459f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd168fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets import (RawDataFromXrDataset)\n",
    "low_rez = low_rez.fillna(0)\n",
    "# low_rez = low_rez.isel(time=slice(0, 3))\n",
    "landmask = RawDataFromXrDataset(low_rez)\n",
    "landmask.add_landmask_input(cnn_field_of_view=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_timemean_log_plt(test,mask):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12,10))\n",
    "    mask1=dataset.isel(time=0)['landmask'].values\n",
    "    S_test = test['S_x']*(1e-7)*dataset.isel(time=0)['landmask']\n",
    "    S_true = low_rez['S_x']*dataset.isel(time=0)['landmask']\n",
    "\n",
    "    #Open water RMSE\n",
    "    maskn=np.where(mask == 0, torch.tensor(float('nan')), mask)\n",
    "\n",
    "    xq = test['xu_ocean']\n",
    "    yq = test['yu_ocean']\n",
    "\n",
    "    # MSE_OW = MSE_snapshot(S_test.mean(dim='time').values*maskn, S_true.mean(dim='time').values*maskn)\n",
    "    RMSE_OW = np.sqrt(((S_test *maskn - S_true*maskn)**2).mean(dim='time'))\n",
    "    RMSE_OW = np.where(RMSE_OW == 0, 1e-30, RMSE_OW)\n",
    "    RMSE_OW_local = float(np.nanmean(RMSE_OW))\n",
    "    p = ax[0].pcolormesh(xq,yq,np.log10(RMSE_OW), \n",
    "        vmin=-8, vmax = -6)\n",
    "    \n",
    "    # create Colormap\n",
    "    colors = [ \"gray\",\"none\"] \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = [0, 0.5, 1]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    # use pcolormesh for landmask\n",
    "    landmask_plot = ax[0].pcolormesh(xq, yq, mask1, cmap=cmap, norm=norm, shading='auto')\n",
    "\n",
    "    # ax[0].set_xlabel('Longitude')\n",
    "    ax[0].set_ylabel('Latitude')\n",
    "    ax[0].set_title('(a) $S_{x}^{(mean)}$: true forcing')\n",
    "    cbar = fig.colorbar(p, ax=ax[0],ticks=[-8, -7, -6], label='Subgrid forcing: $ms^{-2}$')\n",
    "    cbar.ax.set_yticklabels(['$10^{-8}$', '$10^{-7}$', '$10^{-6}$'])\n",
    "\n",
    "    ax[0].set_aspect('equal')\n",
    "    ax[0].set_ylabel('Latitude')\n",
    "    ax[0].set_title('(a) RMSE map for open water:'+f' {RMSE_OW_local:.3e}')\n",
    "\n",
    "    ax[0].set_xlim(xq[20],xq[-20])\n",
    "    ax[0].set_ylim(yq[20],yq[-20])\n",
    "\n",
    "    #Coastal water RMSE\n",
    "    maskn=np.where(mask == 1, torch.tensor(float('nan')), 1)\n",
    "    mask1n=np.where(mask1 == 0, torch.tensor(float('nan')), mask1)\n",
    "    maskn = mask1n*maskn\n",
    "\n",
    "    # MSE_CW = MSE_snapshot(S_test.mean(dim='time').values*maskn, S_true.mean(dim='time').values*maskn)\n",
    "    RMSE_CW = np.sqrt(((S_test *maskn - S_true*maskn)**2).mean(dim='time'))\n",
    "    RMSE_CW = np.where(RMSE_CW == 0, 1e-30, RMSE_CW)\n",
    "    RMSE_CW_local = float(np.nanmean(RMSE_CW))\n",
    "    p = ax[1].pcolormesh(xq,yq,np.log10(RMSE_CW),  \n",
    "        vmin=-8, vmax = -6)\n",
    "    \n",
    "    # create Colormap\n",
    "    colors = [ \"gray\",\"none\"] \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = [0, 0.5, 1]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    # use pcolormesh for landmask\n",
    "    landmask_plot = ax[1].pcolormesh(xq, yq, mask1, cmap=cmap, norm=norm, shading='auto')\n",
    "\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_xlabel('Longitude')\n",
    "    ax[1].set_ylabel('Latitude')\n",
    "    ax[1].set_title('(b) $S_{x}^{(mean)}$: true forcing')\n",
    "    cbar = fig.colorbar(p, ax=ax[1],ticks=[-8, -7, -6], label='Subgrid forcing: $ms^{-2}$')\n",
    "    cbar.ax.set_yticklabels(['$10^{-8}$', '$10^{-7}$', '$10^{-6}$'])\n",
    "    \n",
    "    ax[1].set_ylabel('Latitude')\n",
    "    ax[1].set_title('(b) RMSE map for coastal water:'+f' {RMSE_CW_local:.3e}')\n",
    "\n",
    "    ax[1].set_xlim(xq[20],xq[-20])\n",
    "    ax[1].set_ylim(yq[20],yq[-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a23e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_timemean_log_plt(test1,mask=landmask.isel(time=0)['landmask'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0201674",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_timemean_log_plt(test2,mask=landmask.isel(time=0)['landmask'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91135881",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_timemean_log_plt(test3,mask=landmask.isel(time=0)['landmask'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_0 = xr.open_dataset('test_four_regions_nobc.nc')\n",
    "test2_0 = xr.open_dataset('test_four_regions_0pad.nc')\n",
    "test3_0 = xr.open_dataset('test_four_regions_rpad.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches \n",
    "def RMSD_timemean_diff_plt(test1_0,test2_0,test3_0,test1,test2,test3,mask, xlim=None, ylim=None,cbox1=None,cbox2=None):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(12,15))\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    mask1=dataset.isel(time=0)['landmask'].values\n",
    "    S_test1 = test1['S_x']*(1e-7)*mask1\n",
    "    S_test2 = test2['S_x']*(1e-7)*mask1\n",
    "    S_test3 = test3['S_x']*(1e-7)*mask1\n",
    "    S_test1_0 = test1_0['S_x']*(1e-7)*mask1\n",
    "    S_test2_0 = test2_0['S_x']*(1e-7)*mask1\n",
    "    S_test3_0 = test3_0['S_x']*(1e-7)*mask1\n",
    "    # S_true = low_rez['S_x']\n",
    "\n",
    "    xq = test1['xu_ocean']\n",
    "    yq = test1['yu_ocean']\n",
    "\n",
    "    # create Colormap\n",
    "    colors = [ \"gray\",\"none\"] \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = [0, 0.5, 1]\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "\n",
    "    #Coastal water MSE\n",
    "    maskn=np.where(mask == 1, torch.tensor(float('nan')), 1)\n",
    "    mask1n=np.where(mask1 == 0, torch.tensor(float('nan')), mask1)\n",
    "    maskn = mask1n*maskn\n",
    "\n",
    "    MSE_CW1 = np.sqrt(((S_test1 *maskn - S_test1_0*maskn)**2).mean(dim='time'))\n",
    "    MSE_CW1 = np.where(MSE_CW1 == 0, 1e-30, MSE_CW1)\n",
    "    MSE_CW1_local = float(np.nanmean(MSE_CW1))\n",
    "    p = ax[0].pcolormesh(xq,yq,np.log10(MSE_CW1), \n",
    "        vmin=-8, vmax = -6)\n",
    "    # use pcolormesh for landmask\n",
    "    ax[0].pcolormesh(xq, yq, mask1, cmap=cmap, norm=norm, shading='auto')\n",
    "\n",
    "    # ax[0].set_xlabel('Longitude')\n",
    "    ax[0].set_ylabel('Latitude')\n",
    "    cbar = fig.colorbar(p, ax=ax[0],ticks=[-8, -7, -6], label='Subgrid forcing: $ms^{-2}$')\n",
    "    cbar.ax.set_yticklabels(['$10^{-8}$', '$10^{-7}$', '$10^{-6}$'])\n",
    "    \n",
    "    ax[0].set_title('(a) RMSD map (no BC) for coastal water:'+f' {MSE_CW1_local:.3e}')\n",
    "    ax[0].set_aspect('equal')\n",
    "\n",
    "    if xlim is None:\n",
    "        ax[0].set_xlim(xq[20],xq[-20])\n",
    "        ax[0].set_ylim(yq[20],yq[-20])\n",
    "    else:\n",
    "        ax[0].set_xlim(xlim[0],xlim[1])\n",
    "        ax[0].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "\n",
    "    MSE_CW2 = np.sqrt(((S_test2 *maskn - S_test2_0*maskn)**2).mean(dim='time'))\n",
    "    MSE_CW2 = np.where(MSE_CW2 == 0, 1e-30, MSE_CW2)\n",
    "    MSE_CW2_local = float(np.nanmean(MSE_CW2))\n",
    "    p = ax[1].pcolormesh(xq,yq,np.log10(MSE_CW2), \n",
    "        vmin=-8, vmax = -6)\n",
    "    \n",
    "    # use pcolormesh for landmask\n",
    "    ax[1].pcolormesh(xq, yq, mask1, cmap=cmap, norm=norm, shading='auto')\n",
    "\n",
    "    # ax[1].set_xlabel('Longitude')\n",
    "    ax[1].set_ylabel('Latitude')\n",
    "    cbar = fig.colorbar(p, ax=ax[1],ticks=[-8, -7, -6], label='Subgrid forcing: $ms^{-2}$')\n",
    "    cbar.ax.set_yticklabels(['$10^{-8}$', '$10^{-7}$', '$10^{-6}$'])\n",
    "    \n",
    "    ax[1].set_title('(b) RMSD map (0P) for coastal water:'+f' {MSE_CW2_local:.3e}')\n",
    "    ax[1].set_aspect('equal')\n",
    "\n",
    "    if xlim is None:\n",
    "        ax[1].set_xlim(xq[20],xq[-20])\n",
    "        ax[1].set_ylim(yq[20],yq[-20])\n",
    "    else:\n",
    "        ax[1].set_xlim(xlim[0],xlim[1])\n",
    "        ax[1].set_ylim(ylim[0],ylim[1])\n",
    "    \n",
    "\n",
    "    MSE_CW3 = np.sqrt(((S_test3 *maskn - S_test3_0*maskn)**2).mean(dim='time'))\n",
    "    MSE_CW3 = np.where(MSE_CW3 == 0, 1e-30, MSE_CW3)\n",
    "    MSE_CW3_local = float(np.nanmean(MSE_CW3))\n",
    "    p = ax[2].pcolormesh(xq,yq,np.log10(MSE_CW3), \n",
    "        vmin=-8, vmax = -6)\n",
    "    # use pcolormesh for landmask\n",
    "    ax[2].pcolormesh(xq, yq, mask1, cmap=cmap, norm=norm, shading='auto')\n",
    "    ax[2].set_xlabel('Longitude')\n",
    "    ax[2].set_ylabel('Latitude')\n",
    "    cbar = fig.colorbar(p, ax=ax[2],ticks=[-8, -7, -6], label='Subgrid forcing: $ms^{-2}$')\n",
    "    cbar.ax.set_yticklabels(['$10^{-8}$', '$10^{-7}$', '$10^{-6}$'])\n",
    "    \n",
    "    ax[2].set_title('(b) RMSD map (RP) for coastal water:'+f' {MSE_CW3_local:.3e}')\n",
    "    ax[2].set_aspect('equal')\n",
    "\n",
    "    if xlim is None:\n",
    "        ax[2].set_xlim(xq[20],xq[-20])\n",
    "        ax[2].set_ylim(yq[20],yq[-20])\n",
    "    else:\n",
    "        ax[2].set_xlim(xlim[0],xlim[1])\n",
    "        ax[2].set_ylim(ylim[0],ylim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSD_timemean_diff_plt(test1_0,test2_0,test3_0,test1,test2,test3,mask=landmask.isel(time=0)['landmask'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
